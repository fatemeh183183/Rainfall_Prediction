{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea94cf3",
   "metadata": {},
   "source": [
    " Setup and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2f42a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa19710",
   "metadata": {},
   "source": [
    "Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0896451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001002   Male      No          0      Graduate            No   \n",
      "1  LP001003   Male     Yes          1      Graduate            No   \n",
      "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
      "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
      "4  LP001008   Male      No          0      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0         NaN             360.0   \n",
      "1             4583             1508.0       128.0             360.0   \n",
      "2             3000                0.0        66.0             360.0   \n",
      "3             2583             2358.0       120.0             360.0   \n",
      "4             6000                0.0       141.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area Loan_Status  \n",
      "0             1.0         Urban           Y  \n",
      "1             1.0         Rural           N  \n",
      "2             1.0         Urban           Y  \n",
      "3             1.0         Urban           Y  \n",
      "4             1.0         Urban           Y  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0e0f9",
   "metadata": {},
   "source": [
    "Data Cleaning & Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "060235d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Loan_ID (not useful)\n",
    "df.drop(columns='Loan_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ac60828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features by type\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43d11844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ba6d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b82349a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "target = 'Loan_Status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c74014e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d76857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features by type\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e4cf2c",
   "metadata": {},
   "source": [
    "Pipeline with Imputation, Encoding, and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98edd883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for categorical data\n",
    "# SimpleImputer(strategy='most_frequent'):This fills in missing values in categorical columns using the most common category.\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    " #Converts categorical values like yes or no into binary columns(0 and 1),handle_unknown='ignore' prevents errors when the test set contains unseen categories   \n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "307a7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing for numerical data\n",
    "# SimpleImputer(strategy='median'):fills missing values in numerical columns using the median of each column\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    " # StandardScaler(): Standardizes the numerical features by removing the mean and scalling,to unit variance\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d31867c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numerical_cols),\n",
    "    ('cat', cat_pipeline, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f0c0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Loan_Status'].map({'Y':1,'N':0}).astype(int)\n",
    "x = df.drop(columns='Loan_Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bdf94d",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "addb58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33bc09bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train columns: Index(['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n",
      "       'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
      "       'Loan_Amount_Term', 'Credit_History', 'Property_Area'],\n",
      "      dtype='object')\n",
      "y_train sample: 473    1\n",
      "462    1\n",
      "464    0\n",
      "478    1\n",
      "84     1\n",
      "Name: Loan_Status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train columns:\",X_train.columns)\n",
    "print(\"y_train sample:\", y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b263c",
   "metadata": {},
   "source": [
    "Model + Pipeline (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd0fe501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7580645161290323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.55        19\n",
      "           1       0.79      0.88      0.84        43\n",
      "\n",
      "    accuracy                           0.76        62\n",
      "   macro avg       0.72      0.68      0.69        62\n",
      "weighted avg       0.75      0.76      0.75        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rf = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68649904",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b174c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡 Best rf Accuracy : 0.807960687960688\n",
      "✅ Test Accuracy (rf): 0.7580645161290323\n",
      "📊 rf Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.55        19\n",
      "           1       0.79      0.88      0.84        43\n",
      "\n",
      "    accuracy                           0.76        62\n",
      "   macro avg       0.72      0.68      0.69        62\n",
      "weighted avg       0.75      0.76      0.75        62\n",
      "\n",
      "⚙️ Best Params: {'classifier__max_depth': 5, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 5, 10],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_rf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_preds = best_model.predict(X_test)\n",
    "# Results\n",
    "print(\"💡 Best rf Accuracy :\", grid_search.best_score_)\n",
    "print(\"✅ Test Accuracy (rf):\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"📊 rf Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"⚙️ Best Params:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347a0a2",
   "metadata": {},
   "source": [
    "Try Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fd5df92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡 Best lr Accuracy : 0.8115970515970516\n",
      "✅ Test Accuracy (lr): 0.8225806451612904\n",
      "📊 lr Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.47      0.62        19\n",
      "           1       0.81      0.98      0.88        43\n",
      "\n",
      "    accuracy                           0.82        62\n",
      "   macro avg       0.85      0.73      0.75        62\n",
      "weighted avg       0.84      0.82      0.80        62\n",
      "\n",
      "⚙️ Best Params: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "model_lr = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "param_grid_lr = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__solver': ['liblinear', 'lbfgs'],\n",
    "    'classifier__penalty': ['l2']\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=model_lr,\n",
    "    param_grid=param_grid_lr,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "\n",
    "y_pred_lr = best_lr.predict(X_test)\n",
    "\n",
    "# Results\n",
    "print(\"💡 Best lr Accuracy :\", grid_search_lr.best_score_)\n",
    "print(\"✅ Test Accuracy (lr):\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"📊 lr Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "print(\"⚙️ Best Params:\", grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97243cc4",
   "metadata": {},
   "source": [
    "Try Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4802b1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡 Best SVM Accuracy (CV): 0.807960687960688\n",
      "✅ Test Accuracy (SVM): 0.8225806451612904\n",
      "📊 SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.47      0.62        19\n",
      "           1       0.81      0.98      0.88        43\n",
      "\n",
      "    accuracy                           0.82        62\n",
      "   macro avg       0.85      0.73      0.75        62\n",
      "weighted avg       0.84      0.82      0.80        62\n",
      "\n",
      "⚙️ Best Params: {'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# SVM parameter grid\n",
    "\n",
    "# SVM pipeline with preprocessing\n",
    "model_svm = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "param_grid_svm = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['linear', 'rbf'],\n",
    "    'classifier__gamma': ['scale', 'auto']  # Only used for 'rbf' kernel\n",
    "}\n",
    "\n",
    "# Grid search for SVM\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=model_svm,\n",
    "    param_grid=param_grid_svm,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "# Train\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "# Results\n",
    "print(\"💡 Best SVM Accuracy (CV):\", grid_search_svm.best_score_)\n",
    "print(\"✅ Test Accuracy (SVM):\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"📊 SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"⚙️ Best Params:\", grid_search_svm.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
